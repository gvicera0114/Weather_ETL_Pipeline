{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3ee46d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "import requests\n",
    "#Crear sesión de Spark\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Weather_ETL_Pipeline\") \\\n",
    "    .config(\"spark.driver.extraJavaOptions\", \"-Djava.library.path=C:\\\\hadoop\\\\bin\") \\\n",
    "    .config(\"spark.executor.extraJavaOptions\", \"-Djava.library.path=C:\\\\hadoop\\\\bin\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd368998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener datos meteorológicos de la API\n",
    "url = \"https://api.open-meteo.com/v1/forecast?latitude=18.9261&longitude=-99.2308&hourly=temperature_2m,relative_humidity_2m,wind_speed_10m\"\n",
    "response = requests.get(url)\n",
    "data = response.json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e43da6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procesar datos horarios y crear DataFrame de Spark\n",
    "hourly = data['hourly']\n",
    "rows = list(zip(\n",
    "    hourly['time'],\n",
    "    hourly['temperature_2m'],\n",
    "    hourly['relative_humidity_2m'],\n",
    "    hourly['wind_speed_10m']\n",
    "\n",
    "))\n",
    "hourly_data = spark.createDataFrame(rows, ['time', 'temperature_2m', 'relative_humidity_2m', 'wind_speed_10m'])\n",
    "hourly_data = hourly_data.withColumn(\"time\", F.to_timestamp(F.col(\"time\"), \"yyyy-MM-dd'T'HH:mm\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d5c5527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular promedios diarios\n",
    "df_temp = hourly_data.groupBy(F.to_date(\"time\").alias(\"date\")) \\\n",
    "            .agg(F.avg(\"temperature_2m\").alias(\"avg_temp_daily\")) \\\n",
    "            .orderBy(\"date\")\n",
    "df_humidity = hourly_data.groupBy(F.to_date(\"time\").alias(\"date\")) \\\n",
    "                    .agg(F.avg(\"relative_humidity_2m\").alias(\"avg_humidity_daily\")).orderBy(\"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0870721a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+\n",
      "|      date|    avg_temp_daily|\n",
      "+----------+------------------+\n",
      "|2026-01-14|            18.325|\n",
      "|2026-01-15|           18.4625|\n",
      "|2026-01-16|16.670833333333334|\n",
      "|2026-01-17|19.150000000000002|\n",
      "|2026-01-18|18.212500000000002|\n",
      "|2026-01-19|16.525000000000002|\n",
      "|2026-01-20|17.104166666666668|\n",
      "+----------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_temp.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7452167f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+\n",
      "|      date|avg_humidity_daily|\n",
      "+----------+------------------+\n",
      "|2026-01-14|              50.0|\n",
      "|2026-01-15|             49.75|\n",
      "|2026-01-16|            52.875|\n",
      "|2026-01-17|              54.0|\n",
      "|2026-01-18|             58.75|\n",
      "|2026-01-19|              56.0|\n",
      "|2026-01-20|              54.5|\n",
      "+----------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_humidity.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc22f5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar resultados en archivos Parquet\n",
    "df_temp_pandas = df_temp.toPandas()\n",
    "df_temp_pandas.to_parquet(\"output/avg_temp_daily.parquet\", index=False)\n",
    "df_humidity_pandas = df_humidity.toPandas()\n",
    "df_humidity_pandas.to_parquet(\"output/avg_humidity_daily.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "879c888a",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
